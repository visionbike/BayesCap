{
 "cells": [
  {
   "cell_type": "code",
   "id": "203489cb-fd29-4786-9454-48b92c8004b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:26:22.672831Z",
     "start_time": "2024-07-26T07:26:18.444214Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import SRDataset\n",
    "from loss import *\n",
    "from networks import SRGenerator, SRBayesCap\n",
    "from bayescap import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "a2c004b0-60dd-470c-b43c-0f01ed71cfe2",
   "metadata": {},
   "source": [
    "## Loading the pre-trained (frozen) SRGAN base model and instantiating BayesCap"
   ]
  },
  {
   "cell_type": "code",
   "id": "c3eaaa21-f1c3-43ee-95ae-fe90357d8641",
   "metadata": {
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-26T07:26:22.940205Z",
     "start_time": "2024-07-26T07:26:22.673861Z"
    }
   },
   "source": [
    "device = \"cuda:0\"\n",
    "NetG = SRGenerator()\n",
    "NetG.load_state_dict(torch.load(\"../ckpt/srgan-ImageNet-bc347d67.pth\", map_location=device))\n",
    "# \n",
    "model_parameters = filter(lambda p: True, NetG.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Number of Parameters:\", params)\n",
    "# \n",
    "NetC = SRBayesCap(in_channels=3, out_channels=3)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 1547350\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "12c54acb-de5a-4609-8a9c-0e56c0931522",
   "metadata": {},
   "source": [
    "## Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "id": "6efb4dd2-4ec5-48e2-aeb3-79ad6be21e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:26:23.191811Z",
     "start_time": "2024-07-26T07:26:22.941206Z"
    }
   },
   "source": [
    "dataset_train = SRDataset(data_root=\"../data/SRGAN_ImageNet\", image_size=(86,86), upscale_factor=4, mode=\"train\")\n",
    "dataset_val = SRDataset(data_root=\"../data/Set5/original\", image_size=(256,256), upscale_factor=4, mode=\"val\")\n",
    "dataset_test = SRDataset(data_root=\"../data/Set5/original\", image_size=(256,256), upscale_factor=4, mode=\"test\")\n",
    "\n",
    "loader_train = DataLoader(dataset_train, batch_size=2, pin_memory=True, shuffle=True)\n",
    "loader_val = DataLoader(dataset_val, batch_size=1, pin_memory=True, shuffle=False)\n",
    "loader_test = DataLoader(dataset_test, batch_size=1, pin_memory=True, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "39a421f3-66ed-4ffb-9dd5-f42dc00b41a5",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "ad34e431-1e6a-4edc-a2be-69e93b8c2c8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:26:24.610145Z",
     "start_time": "2024-07-26T07:26:23.192809Z"
    }
   },
   "source": [
    "train_BayesCap(\n",
    "\tNetC,\n",
    "\tNetG,\n",
    "\tloader_train,\n",
    "\tloader_val,\n",
    "\tCri = TempCombLoss(alpha_eps=1e-5, beta_eps=1e-2),\n",
    "\tdevice=device,\n",
    "\tdtype=torch.cuda.FloatTensor,\n",
    "\tinit_lr=1e-4,\n",
    "\tnum_epochs=2000,\n",
    "\teval_every=2,\n",
    "\tckpt_path=\"../ckpt/BayesCap_SRGAN\",\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/2446 [00:01<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (84) must match the size of tensor b (86) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain_BayesCap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mNetC\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mNetG\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mloader_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mloader_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mCri\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mTempCombLoss\u001B[49m\u001B[43m(\u001B[49m\u001B[43malpha_eps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta_eps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFloatTensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m\t\u001B[49m\u001B[43minit_lr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m\t\u001B[49m\u001B[43meval_every\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../ckpt/BayesCap_SRGAN\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\projects\\medical-image-uncertainty\\src\\bayescap.py:257\u001B[0m, in \u001B[0;36mtrain_BayesCap\u001B[1;34m(NetC, NetG, train_loader, eval_loader, Cri, device, dtype, init_lr, num_epochs, eval_every, ckpt_path, T1, T2, task)\u001B[0m\n\u001B[0;32m    255\u001B[0m \u001B[38;5;66;03m# print(xSRC_alpha)\u001B[39;00m\n\u001B[0;32m    256\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m--> 257\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mCri\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxSRC_mu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxSRC_alpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxSRC_beta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxSR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxHR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mT1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mT2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;66;03m# print(loss)\u001B[39;00m\n\u001B[0;32m    259\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\medical-image-uncertainty\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\medical-image-uncertainty\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\projects\\medical-image-uncertainty\\src\\loss.py:133\u001B[0m, in \u001B[0;36mTempCombLoss.forward\u001B[1;34m(self, mean, one_over_alpha, beta, target1, target2, t1, t2)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    124\u001B[0m             mean: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m    125\u001B[0m             one_over_alpha: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;66;03m# target1 is the base model output for identity mapping\u001B[39;00m\n\u001B[0;32m    131\u001B[0m     \u001B[38;5;66;03m# target2 is the ground truth for the GenGauss loss\u001B[39;00m\n\u001B[0;32m    132\u001B[0m     l1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_l1(mean, target1)\n\u001B[1;32m--> 133\u001B[0m     l2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_GenGauss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mone_over_alpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    134\u001B[0m     loss \u001B[38;5;241m=\u001B[39m t1 \u001B[38;5;241m*\u001B[39m l1 \u001B[38;5;241m+\u001B[39m t2 \u001B[38;5;241m*\u001B[39m l2\n\u001B[0;32m    135\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\medical-image-uncertainty\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniforge3\\envs\\medical-image-uncertainty\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\projects\\medical-image-uncertainty\\src\\loss.py:70\u001B[0m, in \u001B[0;36mGenGaussLoss.forward\u001B[1;34m(self, mean, one_over_alpha, beta, target)\u001B[0m\n\u001B[0;32m     68\u001B[0m beta1 \u001B[38;5;241m=\u001B[39m beta \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta_eps\n\u001B[0;32m     69\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m resi \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mabs(\u001B[43mmean\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m)\n\u001B[0;32m     71\u001B[0m \u001B[38;5;66;03m# resi = torch.pow(resi*one_over_alpha1, beta1).clamp(min=self.resi_min, max=self.resi_max)\u001B[39;00m\n\u001B[0;32m     72\u001B[0m resi \u001B[38;5;241m=\u001B[39m (resi \u001B[38;5;241m*\u001B[39m one_over_alpha1 \u001B[38;5;241m*\u001B[39m beta1)\u001B[38;5;241m.\u001B[39mclamp(\u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresi_min, \u001B[38;5;28mmax\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresi_max)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (84) must match the size of tensor b (86) at non-singleton dimension 3"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "da30c18e-9601-452c-ba1d-06daaad3cb76",
   "metadata": {},
   "source": [
    "## Evaluating BayesCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a92f708-0e86-438a-91ea-34222500cb5b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "NetG = SRGenerator()\n",
    "NetG.load_state_dict(torch.load(\"../ckpt/srgan-ImageNet-bc347d67.pth\", map_location=device))\n",
    "NetG.to('cuda')\n",
    "NetG.eval()\n",
    "\n",
    "NetC = SRBayesCap(in_channels=3, out_channels=3)\n",
    "NetC.load_state_dict(torch.load('../ckpt/BayesCap_SRGAN_best.pth', map_location=device))\n",
    "NetC.to('cuda')\n",
    "NetC.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf9b019693a4da",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": "eval_BayesCap(NetC, NetG, loader_test, device=device, dtype=torch.cuda.FloatTensor)"
  },
  {
   "cell_type": "markdown",
   "id": "c6ed8c86-1524-4b15-9781-b94e48c69fd1",
   "metadata": {},
   "source": [
    "## Displaying output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a5e22-e05e-4e83-b8a8-1b68447e9a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cuda'\n",
    "# dtype=torch.cuda.FloatTensor\n",
    "# num_imgs = 0\n",
    "# mean_ssim = 0\n",
    "# for (idx, batch) in enumerate(loader_val):\n",
    "#     print('Image {} ...'.format(idx))\n",
    "#     xLR, xHR = batch[0].to(device), batch[1].to(device)\n",
    "#     xLR, xHR = xLR.type(dtype), xHR.type(dtype)\n",
    "#     # pass them through the network\n",
    "#     with torch.no_grad():\n",
    "#         xSR = NetG(xLR)\n",
    "#         xSRC_mu, xSRC_alpha, xSRC_beta = NetC(xSR)\n",
    "#     n_batch = xSRC_mu.shape[0]\n",
    "#     for j in range(n_batch):\n",
    "#         num_imgs += 1\n",
    "#         mean_ssim += compute_img_ssim(xSRC_mu[j], xHR[j])\n",
    "#         \n",
    "#     plt.figure(figsize=(30,10))\n",
    "#     plt.subplot(1,4,1)\n",
    "#     plt.imshow(xLR[0].to('cpu').data.clip(0,1).transpose(0,2).transpose(0,1))\n",
    "#     plt.axis('off')\n",
    "#     \n",
    "#     plt.subplot(1,4,2)\n",
    "#     plt.imshow(xSR[0].to('cpu').data.clip(0,1).transpose(0,2).transpose(0,1))\n",
    "#     plt.axis('off')\n",
    "#     \n",
    "#     plt.subplot(1,4,3)\n",
    "#     a_map = (1/(xSRC_alpha[0] + 1e-5)).to('cpu').data\n",
    "#     plt.imshow(a_map.transpose(0,2).transpose(0,1), cmap='inferno')\n",
    "#     plt.clim(0, 0.1)\n",
    "#     plt.axis('off')\n",
    "#     \n",
    "#     plt.subplot(1,4,4)\n",
    "#     error_map = torch.mean(torch.pow(torch.abs(xSR[0]-xHR[0]),2), dim=0).to('cpu').data \n",
    "#     plt.imshow(error_map, cmap='jet')\n",
    "#     plt.clim(0,0.01)\n",
    "#     plt.axis('off')\n",
    "#     \n",
    "#     plt.subplots_adjust(wspace=0, hspace=0)\n",
    "#     plt.show()\n",
    "#     ########################\n",
    "#     plt.figure(figsize=(30,10))\n",
    "#     plt.subplot(1,4,1)\n",
    "#     plt.imshow(xHR[0].to('cpu').data.clip(0,1).transpose(0,2).transpose(0,1))\n",
    "#     \n",
    "#     plt.axis('off')\n",
    "#     \n",
    "#     plt.subplot(1,4,2)\n",
    "#     plt.imshow((0.6*xSRC_mu[0]+0.4*xSR[0]).to('cpu').data.clip(0,1).transpose(0,2).transpose(0,1))\n",
    "#     plt.axis('off')\n",
    "#     \n",
    "#     plt.subplot(1,4,3)\n",
    "#     b_map = xSRC_beta[0].to('cpu').data\n",
    "#     plt.imshow(b_map.transpose(0,2).transpose(0,1), cmap='cividis')\n",
    "#     plt.clim(0.45, 0.75)\n",
    "#     plt.axis('off')\n",
    "#     \n",
    "#     plt.subplot(1,4,4)\n",
    "#     u_map = (a_map**2)*(torch.exp(torch.lgamma(3/(b_map + 1e-2)))/torch.exp(torch.lgamma(1/(b_map + 1e-2)))) \n",
    "#     plt.imshow((u_map).transpose(0,2).transpose(0,1), cmap='hot')\n",
    "#     plt.clim(0,0.15)\n",
    "#     plt.axis('off')\n",
    "#     \n",
    "#     plt.subplots_adjust(wspace=0, hspace=0)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
